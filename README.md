# AK4Prompts
IJCAI2024: First work to propose a solution to select optimal prompts by IAA. é¦–ç¯‡åˆ©ç”¨IAAæ¥ç­›é€‰ç”Ÿæˆæ¨¡å‹æœ€ä½³æç¤ºè¯çš„å·¥ä½œ.

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](https://opensource.org/licenses/Apache-2.0)
[![Framework](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?&logo=PyTorch&logoColor=white)](https://pytorch.org/)

This repo contains the official implementation of AK4Prompts of the **IJCAI 2024** paper.

<div align="center">
<h1>
<b>
AK4Prompts: Automated Keywords-Ranking for Prompts in Text-To-Image Models
</b>
</h1>
<h4>
<b>
Haiyang Zhang* , Mengchao Wang* , Shuai He* , Anlong Ming
  
Beijing University of Posts and Telecommunications, *Equal contribution
</b>
</h4>
</div>

### Installation

Create a conda environment with the following command:

```bash
conda create -n ak4prompts python=3.10
conda activate ak4prompts
pip install -r requirements.txt
```

### Inference

Run the `demo.ipynb`

```python
import torch
from diffusers import AutoPipelineForText2Image
from diffusers.utils import make_image_grid
from AK4Prompts import AK4Prompts
from AK4Prompts_pipeline import AK4PromptsPipeline

device = 'cuda:0'
pipeline= AutoPipelineForText2Image.from_pretrained("stabilityai/sdxl-turbo", torch_dtype=torch.float16).to(device)

ak4prompts = AK4Prompts().to(device)
ak4prompts_path = "/checkpoints/SD1.5_LCMLoRA_S4_aes1_clip2.25_hps2.25/pytorch_model.bin"
ak4prompts.load_state_dict(torch.load(ak4prompts_path))
ak4prompts_pipeline = AK4PromptsPipeline(pipeline=pipeline,ak4prompts=ak4prompts,keywords_filename="keywords_list.txt")

prompt = "vase of mixed flowers"

scores_weights = {'aesthetic':1,'clip':5,'hps':3}
prompt_with_keywords = ak4prompts_pipeline.keywords_ranking(prompt=prompt,scores_weights=scores_weights,topk=10)

image = pipeline(prompt=prompt_with_keywords, num_inference_steps=4, guidance_scale=1.0).images[0]
image
```

The `demo.ipynb` script also demonstrates the evolution of images generated by setting different degrees of specific preferences.

<!-- ![hps](images\hps.png "hps") -->
<!-- ![hps](https://github.com/chaochao0/AK4Prompts/tree/master/images/hps.png "hps") -->
<p align="center">
  <img src="https://github.com/chaochao0/AK4Prompts/blob/master/images/hps.png" alt="hps" width="100%">
</p>

### Evaluation

Evaluates the model checkpoint and baselines. Evaluation includes calculating the rewards and storing the images to local.

```bash
python evaluation.py --topk 10 --aes 1.0 --clip 5.0 --hps 3.0 --guidance_scale 1.0
```

`topk`: choose topk keywords

`aes`,`clip`,`hps`: weights for customized keywords-ranking

`guidance_scale`: classifier-free guidance scale for TIS model

### Training Code

Accelerate will automatically handle multi-GPU setting. The code can work on a single GPU, as we automatically handle gradient accumulation as per the available GPUs in the CUDA_VISIBLE_DEVICES environment variable. If you are using a GPU with a small or big RAM, please edit the per_gpu_capacity variable accordingly. 
```bash
accelerate launch train.py --config config/train_config.py:aesthetic_clip_hps
```

## Related Work from Our Group
<table>
  <thead align="center">
    <tr>
      <td><b>ğŸ Projects</b></td>
      <td><b>ğŸ“š Publication</b></td>
      <td><b>ğŸŒˆ Content</b></td>
      <td><b>â­ Stars</b></td>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><a href="https://github.com/woshidandan/Attacker-against-image-aesthetics-assessment-model"><b>Attacker Against IAA Modelã€ç¾å­¦æ¨¡å‹çš„æ”»å‡»å’Œå®‰å…¨è¯„ä¼°æ¡†æ¶ã€‘</b></a></td>
      <td><b>TIP 2025</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Attacker-against-image-aesthetics-assessment-model?style=flat-square&labelColor=343b41"/></td>
    </tr
    <tr>
      <td><a href="https://github.com/woshidandan/Rethinking-Personalized-Aesthetics-Assessment"><b>Personalized Aesthetics Assessmentã€ä¸ªæ€§åŒ–ç¾å­¦è¯„ä¼°æ–°èŒƒå¼ã€‘</b></a></td>
      <td><b>CVPR 2025</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Rethinking-Personalized-Aesthetics-Assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment"><b>Pixel-level image exposure assessmentã€é¦–ä¸ªåƒç´ çº§æ›å…‰è¯„ä¼°ã€‘</b></a></td>
      <td><b>NIPS 2024</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Long-Tail-image-aesthetics-and-quality-assessment"><b>Long-tail solution for image aesthetics assessmentã€ç¾å­¦è¯„ä¼°æ•°æ®ä¸å¹³è¡¡è§£å†³æ–¹æ¡ˆã€‘</b></a></td>
      <td><b>ICML 2024</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Long-Tail-image-aesthetics-and-quality-assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Prompt-DeT"><b>CLIP-based image aesthetics assessmentã€åŸºäºCLIPå¤šå› ç´ è‰²å½©ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>Information Fusion 2024</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Prompt-DeT?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"><b>Compare-based image aesthetics assessmentã€åŸºäºå¯¹æ¯”å­¦ä¹ çš„å¤šå› ç´ ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>ACMMM 2024</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/SR-IAA-image-aesthetics-and-quality-assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Image-Color-Aesthetics-and-Quality-Assessment"><b>Image color aesthetics assessmentã€é¦–ä¸ªè‰²å½©ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>ICCV 2023</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Image-Color-Aesthetics-and-Quality-Assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Image-Aesthetics-and-Quality-Assessment"><b>Image aesthetics assessmentã€é€šç”¨ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>ACMMM 2023</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Image-Aesthetics-and-Quality-Assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/TANet-image-aesthetics-and-quality-assessment"><b>Theme-oriented image aesthetics assessmentã€é¦–ä¸ªå¤šä¸»é¢˜ç¾å­¦è¯„ä¼°ã€‘</b></a></td>
      <td><b>IJCAI 2022</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/TANet-image-aesthetics-and-quality-assessment?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/AK4Prompts"><b>Select prompt based on image aesthetics assessmentã€åŸºäºç¾å­¦è¯„ä¼°çš„æç¤ºè¯ç­›é€‰ã€‘</b></a></td>
      <td><b>IJCAI 2024</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/AK4Prompts?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/mRobotit/M2Beats"><b>Motion rhythm synchronization with beatsã€åŠ¨ä½œä¸éŸµå¾‹å¯¹é½ã€‘</b></a></td>
      <td><b>IJCAI 2024</b></td>
      <td><b>Code, Dataset</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/mRobotit/M2Beats?style=flat-square&labelColor=343b41"/></td>
    </tr>
    <tr>
      <td><a href="https://github.com/woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC"><b>Champion Solution for AIGC Image Quality Assessmentã€NTIRE AIGCå›¾åƒè´¨é‡è¯„ä¼°èµ›é“å† å†›ã€‘</b></a></td>
      <td><b>CVPRW NTIRE 2024</b></td>
      <td><b>Code</b></td>
      <td><img alt="Stars" src="https://img.shields.io/github/stars/woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC?style=flat-square&labelColor=343b41"/></td>
    </tr>
  </tbody>
</table>
